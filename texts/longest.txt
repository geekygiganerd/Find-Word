We turn now to one of the most fundamental problems
of computer science: Given a Boolean formula F(x1, . . . , xn), expressed in so called “conjunctive normal form” as an AND of ORs, can we “satisfy” F by
assigning values to its variables in such a way that F(x1, . . . , xn) = 1? For
example, the formula
F(x1, x2, x3) = (x1 ∨ x¯2) ∧ (x2 ∨ x3) ∧ (¯x1 ∨ x¯3) ∧ (¯x1 ∨ x¯2 ∨ x3) (1)
is satisfied when x1x2x3 = 001. But if we rule that solution out, by defining
G(x1, x2, x3) = F(x1, x2, x3) ∧ (x1 ∨ x2 ∨ x¯3), (2)
then G is unsatisfiable: It has no satisfying assignment.
Section 7.1.1 discussed the embarrassing fact that nobody has ever been
able to come up with an efficient algorithm to solve the general satisfiability
problem, in the sense that the satisfiability of any given formula of size N could
be decided in N O(1) steps. Indeed, the famous unsolved question “does P = NP?”
is equivalent to asking whether such an algorithm exists. We will see in Section
7.9 that satisfiability is a natural progenitor of every NP-complete problem.*
On the other hand enormous technical breakthroughs in recent years have
led to amazingly good ways to approach the satisfiability problem. We now
have algorithms that are much more efficient than anyone had dared to believe
possible before the year 2000. These so-called “SAT solvers” are able to handle
industrial-strength problems, involving millions of variables, with relative ease,
and they’ve had a profound impact on many areas of research such as computer aided verification. In this section we shall study the principles that underlie
modern SAT-solving procedures.
* At the present time very few people believe that P = NP [see SIGACT News 43, 2 (June
2012), 53–77]. In other words, almost everybody who has studied the subject thinks that
satisfiability cannot be decided in polynomial time. The author of this book, however, suspects
that NO(1)-step algorithms do exist, yet that they’re unknowable. Almost all polynomial time
algorithms are so complicated that they lie beyond human comprehension, and could never be
programmed for an actual computer in the real world. Existence is different from embodiment.
2 COMBINATORIAL SEARCHING (F6) 7.2.2.2
To begin, let’s define the problem carefully and simplify the notation, so
that our discussion will be as efficient as the algorithms that we’ll be considering.
Throughout this section we shall deal with variables, which are elements of any
convenient set. Variables are often denoted by x1, x2, x3, . . . , as in (1); but any
other symbols can also be used, like a, b, c, or even d
′′′
74. We will in fact often use
the numerals 1, 2, 3, . . . to stand for variables; and in many cases we’ll find it
convenient to write just j instead of xj , because it takes less time and less space
if we don’t have to write so many x’s. Thus ‘2’ and ‘x2’ will mean the same
thing in many of the discussions below.
A literal is either a variable or the complement of a variable. In other words,
if v is a variable, both v and ¯v are literals. If there are n possible variables in
some problem, there are 2n possible literals. If l is the literal ¯x2, which is also
written ¯2, then the complement of l,
¯l, is x2, which is also written 2.
The variable that corresponds to a literal l is denoted by |l|; thus we have
|v| = |v¯| = v for every variable v. Sometimes we write ±v for a literal that is
either v or ¯v. We might also denote such a literal by σv, where σ is ±1. The
literal l is called positive if |l| = l; otherwise |l| = ¯l, and l is said to be negative.
Two literals l and l
′ are distinct if l ̸= l
′
. They are strictly distinct if |l| ̸= |l
′
|.
A set of literals {l1, . . . , lk} is strictly distinct if |li
| ̸= |lj | for 1 ≤ i < j ≤ k.
The satisfiability problem, like all good problems, can be understood in many
equivalent ways, and we will find it convenient to switch from one viewpoint to
another as we deal with different aspects of the problem. Example (1) is an AND
of clauses, where every clause is an OR of literals; but we might as well regard
every clause as simply a set of literals, and a formula as a set of clauses. With
that simplification, and with ‘xj ’ identical to ‘j’, Eq. (1) becomes
F =
{
{1, ¯2}, {2, 3}, {¯1, ¯3}, {¯1, ¯2, 3}
}
.
And we needn’t bother to represent the clauses with braces and commas either;
we can simply write out the literals of each clause. With that shorthand we’re
able to perceive the real essence of (1) and (2):
F = {1¯2, 23, ¯1¯3, ¯1¯23}, G = F ∪ {12¯3}. (3)
Here F is a set of four clauses, and G is a set of five.
In this guise, the satisfiability problem is equivalent to a covering problem,
analogous to the exact cover problems that we considered in Section 7.2.2.1: Let
Tn =
{
{x1, x¯1}, {x2, x¯2}, . . . , {xn, x¯n}
}
= {1¯1, 2¯2, . . . , nn¯}. (4)
“Given a set F = {C1, . . . , Cm}, where each Ci
is a clause and each clause
consists of literals based on the variables {x1, . . . , xn}, find a set L of n literals
that ‘covers’ F ∪ Tn, in the sense that every clause contains at least one element
of L.” For example, the set F in (3) is covered by L = {¯1, ¯2, 3}, and so is the set
T3; hence F is satisfiable. The set G is covered by {1, ¯1, 2} or {1, ¯1, 3} or · · · or
{¯2, 3, ¯3}, but not by any three literals that also cover T3; so G is unsatisfiable.
Similarly, a family F of clauses is satisfiable if and only if it can be covered
by a set L of strictly distinct literals.
7.2.2.2 SATISFIABILITY 3
If F
′
is any formula obtained from F by complementing one or more variables, it’s clear that F
′
is satisfiable if and only if F is satisfiable. For example,
if we replace 1 by ¯1 and 2 by ¯2 in (3) we obtain
F
′ = {¯12, ¯23, 1¯3, 123}, G′ = F
′ ∪ {¯1¯2¯3}.
In this case F
′
is trivially satisfiable, because each of its clauses contains a
positive literal: Every such formula is satisfied by simply letting L be the set of
positive literals. Thus the satisfiability problem is the same as the problem of
switching signs (or “polarities”) so that no all-negative clauses remain.
Another problem equivalent to satisfiability is obtained by going back to the
Boolean interpretation in (1) and complementing both sides of the equation. By
De Morgan’s laws 7.1.1–(11) and (12) we have
F(x1, x2, x3) = (¯x1 ∧ x2) ∨ (¯x2 ∧ x¯3) ∨ (x1 ∧ x3) ∨ (x1 ∧ x2 ∧ x¯3); (5)
and F is unsatisfiable ⇐⇒ F = 0 ⇐⇒ F = 1 ⇐⇒ F is a tautology. Consequently
F is satisfiable if and only if F is not a tautology: The tautology problem and
the satisfiability problem are essentially the same.*
Since the satisfiability problem is so important, we simply call it SAT. And
instances of the problem such as (1), in which there are no clauses of length
greater than 3, are called 3SAT. In general, kSAT is the satisfiability problem
restricted to instances where no clause has more than k literals.
Clauses of length 1 are called unit clauses, or unary clauses. Binary clauses,
similarly, have length 2; then come ternary clauses, quaternary clauses, and so
forth. Going the other way, the empty clause, or nullary clause, has length 0 and
is denoted by ϵ; it is always unsatisfiable. Short clauses are very important in algorithms for SAT, because they are easier to deal with than long clauses. But long
clauses aren’t necessarily bad; they’re much easier to satisfy than the short ones.
A slight technicality arises when we consider clause length: The binary
clause (x1 ∨ x¯2) in (1) is equivalent to the ternary clause (x1 ∨ x1 ∨ x¯2) as well
as to (x1 ∨ x¯2 ∨ x¯2) and to longer clauses such as (x1 ∨ x1 ∨ x1 ∨ x¯2); so we can
regard it as a clause of any length ≥ 2. But when we think of clauses as sets
of literals rather than ORs of literals, we usually rule out multisets such as 11¯2
or 1¯2¯2 that aren’t sets; in that sense a binary clause is not a special case of a
ternary clause. On the other hand, every binary clause (x ∨ y) is equivalent to
two ternary clauses, (x ∨ y ∨ z) ∧ (x ∨ y ∨ z¯), if z is another variable; and every
k-ary clause is equivalent to two (k + 1)-ary clauses. Therefore we can assume,
if we like, that kSAT deals only with clauses whose length is exactly k.
A clause is tautological (always satisfied) if it contains both v and ¯v for some
variable v. Tautological clauses can be denoted by ℘ (see exercise 7.1.4–222).
They never affect a satisfiability problem; so we usually assume that the clauses
input to a SAT-solving algorithm consist of strictly distinct literals.
When we discussed the 3SAT problem briefly in Section 7.1.1, we took a
look at formula 7.1.1–(32), “the shortest interesting formula in 3CNF.” In our
* Strictly speaking, TAUT is coNP-complete, while SAT is NP-complete; see Section 7.9.
4 COMBINATORIAL SEARCHING (F6) 7.2.2.2
new shorthand, it consists of the following eight unsatisfiable clauses:
R = {12¯3, 23¯4, 341, 4¯12, ¯1¯23, ¯2¯34, ¯3¯4¯1, ¯41¯2}. (6)
This set makes an excellent little test case, so we will refer to it frequently below.
(The letter R reminds us that it is based on R. L. Rivest’s associative block design
6.5–(13).) The first seven clauses of R, namely
R
′ = {12¯3, 23¯4, 341, 4¯12, ¯1¯23, ¯2¯34, ¯3¯4¯1}, (7)
also make nice test data; they are satisfied only by choosing the complements of
the literals in the omitted clause, namely {4, ¯1, 2}. More precisely, the literals
4, ¯1, and 2 are necessary and sufficient to cover R′
; we can also include either 3
or ¯3 in the solution. Notice that (6) is symmetric under the cyclic permutation
1 → 2 → 3 → 4 → ¯1 → ¯2 → ¯3 → ¯4 → 1 of literals; thus, omitting any clause
of (6) gives a satisfiability problem equivalent to (7).
A simple example. SAT solvers are important because an enormous variety
of problems can readily be formulated Booleanwise as ANDs of ORs. Let’s begin
with a little puzzle that leads to an instructive family of example problems:
Find a binary sequence x1 . . . x8 that has no three equally spaced 0s and no
three equally spaced 1s. For example, the sequence 01001011 almost works; but
it doesn’t qualify, because x2, x5, and x8 are equally spaced 1s.
If we try to solve this puzzle by backtracking manually through all 8-bit
sequences in lexicographic order, we see that x1x2 = 00 forces x3 = 1. Then
x1x2x3x4x5x6x7 = 0010011 leaves us with no choice for x8. A minute or two of
further hand calculation reveals that the puzzle has just six solutions, namely
00110011, 01011010, 01100110, 10011001, 10100101, 11001100. (8)
Furthermore it’s easy to see that none of these solutions can be extended to a
suitable binary sequence of length 9. We conclude that every binary sequence
x1 . . . x9 contains three equally spaced 0s or three equally spaced 1s.
Notice now that the condition x2x5x8 ̸= 111 is the same as the Boolean
clause (¯x2 ∨ x¯5 ∨ x¯8), namely ¯2¯5¯8. Similarly x2x5x8 ̸= 000 is the same as 258.
So we have just verified that the following 32 clauses are unsatisfiable:
123, 234, . . . , 789, 135, 246, . . . , 579, 147, 258, 369, 159,
¯1¯2¯3, ¯2¯3¯4, . . . , ¯7¯8¯9, ¯1¯3¯5, ¯2¯4¯6, . . . , ¯5¯7¯9, ¯1¯4¯7, ¯2¯5¯8, ¯3¯6¯9, ¯1¯5¯9. (9)
This result is a special case of a general fact that holds for any given positive
integers j and k: If n is sufficiently large, every binary sequence x1 . . . xn contains
either j equally spaced 0s or k equally spaced 1s. The smallest such n is denoted
by W(j, k) in honor of B. L. van der Waerden, who proved an even more general
result (see exercise 2.3.4.3–6): If n is sufficiently large, and if k0, . . . , kb−1 are
positive integers, every b-ary sequence x1 . . . xn contains ka equally spaced a’s
for some digit a, 0 ≤ a < b. The least such n is W(k0, . . . , kb−1).
Let us accordingly define the following set of clauses when j, k, n > 0:
waerden(j, k; n) = {
(xi ∨ xi+d ∨ · · · ∨ xi+(j−1)d)
⏐
⏐ 1 ≤ i ≤ n − (j−1)d, d ≥ 1
}
∪
{
(¯xi ∨ x¯i+d ∨ · · · ∨ x¯i+(k−1)d)
⏐
⏐ 1 ≤ i ≤ n − (k−1)d, d ≥ 1
}
. (10)
7.2.2.2 SATISFIABILITY: EXAMPLE APPLICATIONS 5
The 32 clauses in (9) are waerden(3, 3; 9); and in general waerden(j, k; n) is an
appealing instance of SAT, satisfiable if and only if n < W(j, k).
It’s obvious that W(1, k) = k and W(2, k) = 2k−[k even]; but when j and k
exceed 2 the numbers W(j, k) are quite mysterious. We’ve seen that W(3, 3) = 9,
and the following nontrivial values are currently known:
k = 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19
W(3, k) = 9 18 22 32 46 58 77 97 114 135 160 186 218 238 279 312 349
W(4, k) = 18 35 55 73 109 146 309 ? ? ? ? ? ? ? ? ? ?
W(5, k) = 22 55 178 206 260 ? ? ? ? ? ? ? ? ? ? ? ?
W(6, k) = 32 73 206 1132 ? ? ? ? ? ? ? ? ? ? ? ? ?
V. Chvátal inaugurated the study of W(j, k) by computing the values for j+k ≤ 9
as well as W(3, 7) [Combinatorial Structures and Their Applications (1970), 31–
33]. Most of the large values in this table have been calculated by state-of-the-art
SAT solvers [see M. Kouril and J. L. Paul, Experimental Math. 17 (2008), 53–
61; M. Kouril, Integers 12 (2012), A46:1–A46:13]. The table entries for j = 3
suggest that we might have W(3, k) < k2 when k > 4, but that isn’t true: SAT
solvers have also been used to establish the lower bounds
k = 20 21 22 23 24 25 26 27 28 29 30
W(3, k) ≥ 389 416 464 516 593 656 727 770 827 868 903
(which might in fact be the true values for this range of k); see T. Ahmed,
O. Kullmann, and H. Snevily [Discrete Applied Math. 174 (2014), 27–51].
Notice that the literals in every clause of waerden(j, k; n) have the same
sign: They’re either all positive or all negative. Does this “monotonic” property
make the SAT problem any easier? Unfortunately, no: Exercise 10 proves that
any set of clauses can be converted to an equivalent set of monotonic clauses.
Exact covering. The exact cover problems that we solved with “dancing links”
in Section 7.2.2.1 can easily be reformulated as instances of SAT and handed off
to SAT solvers. For example, let’s look again at Langford pairs, the task of
placing two 1s, two 2s, . . . , two n’s into 2n slots so that exactly k slots intervene
between the two appearances of k, for each k. The corresponding exact cover
problem when n = 3 has nine columns and eight rows (see 7.2.2.1–(00)):
d1 s1 s3, d1 s2 s4, d1 s3 s5, d1 s4 s6, d2 s1 s4, d2 s2 s5, d2 s3 s6, d3 s1 s5. (11)
The columns are di for 1 ≤ i ≤ 3 and sj for 1 ≤ j ≤ 6; the row ‘di sj sk’ means
that digit i is placed in slots j and k. Left-right symmetry allows us to omit the
row ‘d3 s2 s6’ from this specification.
We want to select rows of (11) so that each column appears just once. Let
the Boolean variable xj mean ‘select row j’, for 1 ≤ j ≤ 8; the problem is then
to satisfy the nine constraints
S1(x1, x2, x3, x4) ∧ S1(x5, x6, x7) ∧ S1(x8)
∧ S1(x1, x5, x8) ∧ S1(x2, x6) ∧ S1(x1, x3, x7)
∧ S1(x2, x4, x5) ∧ S1(x3, x6, x8) ∧ S1(x4, x7), (12)
6 COMBINATORIAL SEARCHING (F6) 7.2.2.2
one for each column. (Here, as usual, S1(y1, . . . , yp) denotes the symmetric
function [y1 + · · · + yp = 1].) For example, we must have x5 + x6 + x7 = 1,
because column d2 appears in rows 5, 6, and 7 of (11).
One of the simplest ways to express the symmetric Boolean function S1 as
an AND of ORs is to use 1 + (
p
2
)
clauses:
S1(y1, . . . , yp) = (y1 ∨ · · · ∨ yp) ∧
⋀
1≤j<k≤p
(¯yj ∨ y¯k). (13)
“At least one of the y’s is true, but not two.” Then (12) becomes, in shorthand,
{1234, ¯1¯2, ¯1¯3, ¯1¯4, ¯2¯3, ¯2¯4, ¯3¯4, 567, ¯5¯6, ¯5¯7, ¯6¯7, 8,
158, ¯1¯5, ¯1¯8, ¯5¯8, 26, ¯2¯6, 137, ¯1¯3, ¯1¯7, ¯3¯7,
245, ¯2¯4, ¯2¯5, ¯4¯5, 368, ¯3¯6, ¯3¯8, ¯6¯8, 47, ¯4¯7}; (14)
we shall call these clauses langford (3). (Notice that only 30 of them are actually
distinct, because ¯1¯3 and ¯2¯4 appear twice.) Exercise 13 defines langford (n); we
know from exercise 7–1 that langford (n) is satisfiable ⇐⇒ n mod 4 = 0 or 3.
The unary clause 8 in (14) tells us immediately that x8 = 1. Then from the
binary clauses ¯1¯8, ¯5¯8, ¯3¯8, ¯6¯8 we have x1 = x5 = x3 = x6 = 0. The ternary clause
137 then implies x7 = 1; finally x4 = 0 (from ¯4¯7) and x2 = 1 (from 1234). Rows
8, 7, and 2 of (11) now give us the desired Langford pairing 3 1 2 1 3 2.
Incidentally, the function S1(y1, y2, y3, y4, y5) can also be expressed as
(y1 ∨ y2 ∨ y3 ∨ y4 ∨ y5) ∧ (¯y1∨ y¯2) ∧ (¯y1∨ y¯3) ∧ (¯y1∨¯t)
∧ (¯y2∨ y¯3) ∧ (¯y2∨¯t) ∧ (¯y3∨¯t) ∧ (t ∨ y¯4) ∧ (t ∨ y¯5) ∧ (¯y4∨ y¯5),
where t is a new variable. In general, if p gets big, it’s possible to express
S1(y1, . . . , yp) with only 3p−5 clauses instead of (
p
2
)
+1, by using ⌊(p−3)/2⌋ new
variables as explained in exercise 12. When this alternative encoding is used to
represent Langford pairs of order n, we’ll call the resulting clauses langford ′
(n).
Do SAT solvers do a better job with the clauses langford (n) or langford ′
(n)?
Stay tuned: We’ll find out later.
